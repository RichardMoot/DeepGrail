{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM part-of-speech tagging and supertagging for the French Treebank: \n",
    "\n",
    "This notebook trains a part-of-speech tagger and supertagger for the French Treebank using a vanilla bi-direction LSTM network.\n",
    "\n",
    "Run the following cell to load the Keras packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Bidirectional, Dense, Input, Dropout, LSTM, Activation, TimeDistributed, BatchNormalization, concatenate, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.constraints import max_norm\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from grail_data_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the TLGbank file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences with verified parses\n",
    "# number of sentences, train: 9449, test: 3150, dev: 3150\n",
    "words, Y1, Y2, S, vocabulary, vnorm, partsofspeech1, partsofspeech2, superset, maxLen = read_maxentdata('parsed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longest sentence   :  140\n",
      "Number of POS tags :  32\n",
      "Number of supertags:  891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print()\n",
    "print(\"Longest sentence   : \", maxLen)\n",
    "print(\"Number of POS tags : \", numClasses)\n",
    "print(\"Number of supertags: \", numSuperClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the input into train/dev/test\n",
    "\n",
    "Split the full training set into 60% train, 20% dev and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create auxiliary mappings\n",
    "\n",
    "Create mappings from supertags and the two sets of part-of-speech tags to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_to_index = load_obj('super_to_index')\n",
    "index_to_super = load_obj('index_to_super')\n",
    "pos1_to_index = load_obj('pos1_to_index')\n",
    "index_to_pos1 = load_obj('index_to_pos1')\n",
    "pos2_to_index = load_obj('pos2_to_index')\n",
    "index_to_pos2 = load_obj('index_to_pos2')\n",
    "p1_to_integer = load_obj('p1_to_integer')\n",
    "integer_to_p1 = load_obj('integer_to_p1')\n",
    "p2_to_integer = load_obj('p2_to_integer')\n",
    "integer_to_p2 = load_obj('integer_to_p2')\n",
    "p3_to_integer = load_obj('p3_to_integer')\n",
    "integer_to_p3 = load_obj('integer_to_p3')\n",
    "p4_to_integer = load_obj('p4_to_integer')\n",
    "integer_to_p4 = load_obj('integer_to_p4')\n",
    "s1_to_integer = load_obj('s1_to_integer')\n",
    "integer_to_s1 = load_obj('integer_to_s1')\n",
    "s2_to_integer = load_obj('s2_to_integer')\n",
    "integer_to_s2 = load_obj('integer_to_s2')\n",
    "s3_to_integer = load_obj('s3_to_integer')\n",
    "integer_to_s3 = load_obj('integer_to_s3')\n",
    "s4_to_integer = load_obj('s4_to_integer')\n",
    "integer_to_s4 = load_obj('integer_to_s4')\n",
    "s5_to_integer = load_obj('s5_to_integer')\n",
    "integer_to_s5 = load_obj('integer_to_s5')\n",
    "s6_to_integer = load_obj('s6_to_integer')\n",
    "integer_to_s6 = load_obj('integer_to_s6')\n",
    "s7_to_integer = load_obj('s7_to_integer')\n",
    "integer_to_s7 = load_obj('integer_to_s7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numSuperClasses = len(index_to_super) + 1\n",
    "\n",
    "Y = lists_to_indices(S, super_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 221.  599.  264.  890.   11.  597.  319.   38.  264.  890.   11.  597.\n",
      "  653.  597.  315.   20.  585.  756.   11.  597.  174.   11.  597.   57.\n",
      "    1.  597.  653.  597.  319.  162.   11.  597.   57.    1.  597.  319.\n",
      "  174.   11.  597.  319.  315.  330.  832.  221.  609.  426.  387.  597.\n",
      "  429.   11.  597.  319.  653.  597.  174.  221.  653.  597.  315.  162.\n",
      "   11.  597.  319.  653.  597.  629.   11.  597.  724.  361.   11.  597.\n",
      "   57.  597.  174.  221.  315.  447.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "(4320, 140)\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2795, 140)\n"
     ]
    }
   ],
   "source": [
    "Yin = Y[:2795]\n",
    "print(np.shape(Yin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        out = []\n",
    "        for line in f:\n",
    "            list = []\n",
    "            line = line.strip().split()\n",
    "            for i in line:\n",
    "                list.append(i)\n",
    "            out.append(list)\n",
    "    return np.asarray(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeftList  = read_data('brackets_left.txt')\n",
    "RightList = read_data('brackets_right.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l_to_indices(X, max_len):\n",
    "\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
    "    X_indices = np.zeros((m,max_len,1))\n",
    "\n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split it into words. You should get a list of words.\n",
    "        list = X[i]\n",
    "\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in list:\n",
    "            try:\n",
    "                X_indices[i, j, 0] = float(w)\n",
    "            except:\n",
    "                print(\"Not a float/integer: \", w)\n",
    "                X_indices[i, j, 0] = 0  # unknown\n",
    "            # Increment j to j + 1\n",
    "            j = j + 1\n",
    "            \n",
    "    return X_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Left = l_to_indices(LeftList, maxLen)\n",
    "Right = l_to_indices(RightList, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  2.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  2.  0.  1.  2.\n",
      "  1.  1.  1.  4.  0.  1.  2.  1.  1.  0.  0.  1.  2.  0.  1.  2.  1.  0.\n",
      "  1.  1.  1.  0.  2.  0.  1.  3.  1.  0.  1.  0.  1.  2.  4.  0.  1.  0.\n",
      "  1.  0.  1.  0.  2.  0.  1.  2.  0.  1.  0.  1.  2.  0.  2.  0.  2.  0.\n",
      "  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "(2795, 140)\n"
     ]
    }
   ],
   "source": [
    "print(Left[0])\n",
    "print(np.shape(Left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_indices = Input(shape = (maxLen,), dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = Embedding(numSuperClasses,64,trainable=True,mask_zero=True)(sentence_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(emb)\n",
    "X = Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = TimeDistributed(Dense(32,kernel_constraint=max_norm(5.)))(X)\n",
    "Z = TimeDistributed(Dense(32,kernel_constraint=max_norm(5.)))(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "L =  TimeDistributed(Dense(1,kernel_constraint=max_norm(5.)))(Y)\n",
    "outl = Activation('relu')(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R =  TimeDistributed(Dense(1,kernel_constraint=max_norm(5.)))(Z)\n",
    "outr = Activation('relu')(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 140)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 140, 64)      57024       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 140, 512)     657408      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 140, 512)     1574912     bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 140, 32)      16416       bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 140, 32)      16416       bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 140, 1)       33          time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 140, 1)       33          time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 140, 1)       0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 140, 1)       0           time_distributed_24[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 2,322,242\n",
      "Trainable params: 2,322,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(sentence_indices, [outl, outr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse','mse']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2236 samples, validate on 559 samples\n",
      "Epoch 1/30\n",
      "2236/2236 [==============================] - 159s 71ms/step - loss: 6.9297 - activation_16_loss: 1.0293 - activation_17_loss: 5.9004 - val_loss: 5.0428 - val_activation_16_loss: 0.5925 - val_activation_17_loss: 4.4504\n",
      "Epoch 2/30\n",
      "2048/2236 [==========================>...] - ETA: 11s - loss: 2.8932 - activation_16_loss: 0.6096 - activation_17_loss: 2.2835"
     ]
    }
   ],
   "source": [
    "history = model.fit(Yin, [Left,Right], epochs=30, batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lpred, Rpred = model.predict(Y[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 140, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Lpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.93247151  0.99550194  0.          3.08669186  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Lpred[1000,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(ws, left, right):\n",
    "    li = left.astype(int)\n",
    "    ri = right.astype(int)\n",
    "    for i in range(len(ws)):\n",
    "        open = li[i]\n",
    "        print(\"(\"*open, end=' ')\n",
    "        print(ws[i], end=' ')\n",
    "        close = ri[i]\n",
    "        print(\")\"*close, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_predict(sentno):\n",
    "    print_prediction(words[sentno], Lpred[sentno,:,0], Rpred[sentno,:,0])\n",
    "    print(\"\")\n",
    "    print_prediction(words[sentno], Left[sentno,:,0], Right[sentno,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( D'  ( autres  ( idÃ©es  ( sont  ( Ã    l' )))) (( Ã©tude   :  ( la  (( crÃ©ation   d'  ( une  ( entreprise   de ) ( pÃ¢tisserie   orientale  ( qui  (( vendrait   ses  (( produits   aux )  restaurants   d' ))) ( entreprises   , )))))))  une   fabrique   de   bijoux   fantaisie   ,   une   entreprise   de   collecte   de   vÃªtements   dans   la   foulÃ©e   d'   EmmaÃ¼s   .  \n",
      "((( D'  ( autres   idÃ©es )) ( sont  ( Ã   ( l'   Ã©tude )))) ( :  (( la  ( crÃ©ation  ( d'  ( une  (( entreprise  ( de  ( pÃ¢tisserie   orientale ))) ( qui  (( vendrait  ( ses   produits )) ( aux  ( restaurants  ( d'   entreprises )))))))))) ( ,  (( une  ( fabrique  ( de  ( bijoux   fantaisie )))) ( ,  ( une  (( entreprise  ( de  ( collecte  ( de   vÃªtements )))) ( dans  ( la  ( foulÃ©e  ( d'   EmmaÃ¼s ))))))))))))  .  "
     ]
    }
   ],
   "source": [
    "parse_predict(1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(( Une  ( entreprise  ( de  ( conditionnement   , ))) (( France-MaÃ®trise   ,   serait  ( d'  (( accord   pour  ( dÃ©marrer   une )  entreprise  ( d'  ( insertion  ( sur   la )))))))  commune   .  "
     ]
    }
   ],
   "source": [
    "print_prediction(words[1003], Lpred[1003,:,0], Rpred[1003,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((( Une  ( entreprise  ( de   conditionnement ))) ( ,   France-MaÃ®trise )) ((( ,   serait ) ( d'   accord )) ( pour  (( dÃ©marrer  ( une  ( entreprise  ( d'   insertion )))) ( sur  ( la   commune ))))))  .  "
     ]
    }
   ],
   "source": [
    "print_prediction(words[1003], Left[1003,:,0], Right[1003,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Son', 'rÃ´le', ':', 'crÃ©er', 'une', 'synergie', 'entre', 'organismes', 'et', 'associations', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.51808262]\n",
      " [ 0.        ]\n",
      " [ 1.06027424]\n",
      " [ 0.        ]\n",
      " [ 2.71995115]\n",
      " [ 0.        ]\n",
      " [ 2.04945779]\n",
      " [ 0.        ]\n",
      " [ 1.07729733]\n",
      " [ 1.14353406]\n",
      " [ 0.44215032]\n",
      " [ 1.10520411]\n",
      " [ 1.05459976]\n",
      " [ 0.        ]\n",
      " [ 2.13619494]\n",
      " [ 0.        ]\n",
      " [ 1.00193095]\n",
      " [ 0.99981958]\n",
      " [ 1.06076026]\n",
      " [ 1.04573667]\n",
      " [ 1.08062315]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Lpred[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 1.01456225]\n",
      " [ 0.        ]\n",
      " [ 2.68298173]\n",
      " [ 0.        ]\n",
      " [ 0.93558681]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 1.7421037 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 6.3043251 ]\n",
      " [ 0.        ]\n",
      " [ 1.07220888]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 9.12233067]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Rpred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
