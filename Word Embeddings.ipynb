{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, Dense, Input, Dropout, LSTM, Activation, TimeDistributed, BatchNormalization, concatenate, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from grail_data_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# entire corpus\n",
    "X, Y1, Y2, Z, vocabulary, vnorm, partsofspeech1, partsofspeech2, superset, maxLen = read_maxentdata('m2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longest sentence      :  266\n",
      "Number of words       :  30300\n",
      "Number of norm. words :  28223\n",
      "Number of POS tags    :  32\n",
      "Number of supertags   :  891\n"
     ]
    }
   ],
   "source": [
    "numClasses = len(partsofspeech2)+1\n",
    "numSuperClasses = len(superset)+1\n",
    "\n",
    "print()\n",
    "print(\"Longest sentence      : \", maxLen)\n",
    "print(\"Number of words       : \", len(vocabulary))\n",
    "print(\"Number of norm. words : \", len(vnorm))\n",
    "print(\"Number of POS tags    : \", numClasses)\n",
    "print(\"Number of supertags   : \", numSuperClasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features(string, cat):\n",
    "    fset = set()\n",
    "\n",
    "    if (cat == \"v\"):\n",
    "        m0 = re.search(r\"<(.*)>\", string)\n",
    "        if m0 is not None:\n",
    "            for item in m0.group(1).split(','):\n",
    "                fset.add(item)\n",
    "\n",
    "    m1 = re.search(r\"cat=(.*?)[,\\]]\", string)\n",
    "    if m1 is not None:\n",
    "        fset.add(m1.group(1))\n",
    "\n",
    "    for m2 in re.findall(r\"@(.*?)[,\\]]\", string):\n",
    "        if not (m2 == \"e\"):\n",
    "            fset.add(m2)\n",
    "    return fset\n",
    "            \n",
    "    \n",
    "def read_lefff(file):\n",
    "    vocabulary = set()\n",
    "    tags = set()\n",
    "    word_pos_map = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            w = line[0]\n",
    "            wlist = w.split()\n",
    "            if (len(wlist) == 2):\n",
    "                w = wlist[0]\n",
    "                nextfeat == None\n",
    "                if (wlist[1]).startswith(\"qu'\"):\n",
    "                    nextfeat = \"Next:que\"\n",
    "                if (wlist[1]).startswith(\"que \"):\n",
    "                    nextfeat = \"Next:que\"\n",
    "                if (wlist[1] == 'que'):\n",
    "                    nextfeat = \"Next:que\"\n",
    "                if (wlist[1]).startswith(\"d'\"):\n",
    "                    nextfeat = \"Next:de\"\n",
    "                if (wlist[1]).startswith(\"de \"):\n",
    "                    nextfeat = \"Next:de\"\n",
    "                if (wlist[1] == 'de'):\n",
    "                    nextfeat = \"Next:de\"\n",
    "                if (wlist[1]).startswith(\"à \"):\n",
    "                    nextfeat = \"Next:à\"\n",
    "                if (wlist[1] == 'à'):\n",
    "                    nextfeat = \"Next:à\"\n",
    "                if (wlist[1] == 'priori'):\n",
    "                    nextfeat = \"Next:priori\"\n",
    "            elif (len(wlist) == 1):\n",
    "                nextfeat = None\n",
    "                \n",
    "            if (len(wlist) == 1) or ((len(wlist) ==2) and (nextfeat is not None)):    \n",
    "                pos = line[2]\n",
    "                features = line[3]\n",
    "                vocabulary.add(w)\n",
    "                valset = word_pos_map.get(w)\n",
    "                if valset is None:\n",
    "                    valset = set()\n",
    "                valset.add(pos)\n",
    "                fts = get_features(features, pos)\n",
    "                valset = valset.union(fts)\n",
    "                if nextfeat is not None:\n",
    "                    valset.add(nextfeat)\n",
    "                word_pos_map[w] = valset\n",
    "\n",
    "    for w in ['capella', 'contratio', 'fortiori', 'latere', 'minima', 'posteriori',  'priori']:\n",
    "        word_pos_map[w] = set(['priori'])\n",
    "                \n",
    "    for key in iter(word_pos_map.keys()):\n",
    "        word_pos_map[key] = frozenset(word_pos_map[key])\n",
    "        \n",
    "    for val in iter(word_pos_map.values()):\n",
    "        tags.add(val)\n",
    "        \n",
    "    return vocabulary, tags, word_pos_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t, wpm = read_lefff('lefff-ext-3.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"Jean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"est\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"été\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"était\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"faut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"que\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"qu'\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"priori\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wpm[\"importe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fset = set()\n",
    "for frozen in t:\n",
    "    for f in frozen:\n",
    "        fset.add(f)\n",
    "print(fset)\n",
    "print(len(fset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
